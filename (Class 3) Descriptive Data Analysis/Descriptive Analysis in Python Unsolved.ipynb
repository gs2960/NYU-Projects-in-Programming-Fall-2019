{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All material ©2019, Alex Siegman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Descriptive Analysis in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd # importing the Pandas library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#####  For a full list of all the possible Pandas operations:  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd # AKA, 'Print Working Directory' – tells us what folder I am in right now.\n",
    "\n",
    "# think of this like using your mouse to click into and out of folders on your desktop. \n",
    "# this is just bypassing that UI.\n",
    "\n",
    "# the '!' allows you to execute a shell command. Basically, you're working as if you would in \n",
    "# your terminal, but from the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls # list all of the files in the current directory (remember, directory = folder in UI world).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./SternTech_UserData.csv',encoding='utf-8') # read in the csv\n",
    "\n",
    "# we are setting our dataset equal to the value 'df'.\n",
    "# we can name this anything at all, it doesn't matter.\n",
    "# df is commonplace, though, and stands for 'data frame'.\n",
    "\n",
    "# you can ignore the 'encoding' piece for now, we'll get to that later on when we talk about web scraping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 2000 # the way Jupyter Notebook tends to display the results of such queries isn't \n",
    "                                   # always helpful, but we can very easily change that.\n",
    "                                   # this will ensure we can view up to 2,000 rows without seeing elipses in the UI\n",
    "    \n",
    "pd.options.display.max_columns = 50 # try commenting out this last line ('max_columns =50') then run the cell below\n",
    "                                    # to see the difference this formatting makes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop that \"unnamed\" column \n",
    "\n",
    "df = df.drop(df.columns[[0]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # this gets the first five rows of data in your data frame \n",
    "          # df.tail() will give you the last five rows\n",
    "          # if you want, you can choose any number - df.head(15) would give you the first 15 rows, for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df) # get a list of all the column names for your data frame\n",
    "\n",
    "# we'll discuss this later on, but note that a list is comprised of comma-separated values inside of square brackets\n",
    "# you can also use \"df.columns\" if you prefer, which will give you a similar output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # get the basic statitical metrics for a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = \n",
    "age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = \n",
    "age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Time...\n",
    "\n",
    "#### https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime # import the datetime library "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are three major ways you can deal with time in Pandas: \n",
    "\n",
    "1. Timestamps (DatetimeIndex, datetime64)\n",
    "2. Periods / Timespans (PeriodIndex, period[freq]) \n",
    "3. Timedeltas (TimedeltaIndex, timedelta64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamps \n",
    "\n",
    "timestamps = pd.Timestamp(datetime.datetime(2019, 5, 9))\n",
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# periods\n",
    "\n",
    "periods = pd.Series(pd.period_range('1/1/2019', freq='M', periods=3))\n",
    "periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's important to note that both timestamps and periods can serve as an index. \n",
    "\n",
    "#### Remember, an index is a way to access a data point in a data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # let's reset our index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # check the first five rows of our datset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # convert to datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # make sure we've properly converted from str to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # set our index to the timestamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # check the first five rows of our dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "periods =  # let's group by month \n",
    "periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date =  # set an arbitray start date\n",
    "end_date =  # set an arbitray end date\n",
    "\n",
    "mask =  # create our mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = \n",
    "df # check our mask results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Variables:\n",
    "\n",
    "Often times, you will have Yes / No values, or categorical variables, that you need to transform into numerical data. The easiest way to do that is with dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last but not least, a bit of Data Viz:\n",
    "\n",
    "_P.S. We'll delve much further into data viz later on in this course, so don't worry if this appears too basic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot() # note that it's only going to plot the numerical data, and it isn't very helpful..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot() # not very helpful, but easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
